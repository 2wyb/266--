import matplotlib.pyplot as pyplot # 引入画图依赖
import math

# 模拟一个简单的梯度下降算法,用于理解深度学习的模型训练过程
# X = [0.01 * i for i in range(100)]
# Y = [9 * x ** 2 + x + 8 for x in X]
# print(X)
# print(Y)

# 自定义模型 训练集
X = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35000000000000003, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41000000000000003, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47000000000000003, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.5700000000000001, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.6900000000000001, 0.7000000000000001, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.8200000000000001, 0.8300000000000001, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.9400000000000001, 0.9500000000000001, 0.96, 0.97, 0.98, 0.99]
Y = [8.0, 8.0109, 8.0236, 8.0381, 8.0544, 8.0725, 8.0924, 8.1141, 8.1376, 8.1629, 8.19, 8.2189, 8.2496, 8.2821, 8.3164, 8.3525, 8.3904, 8.4301, 8.4716, 8.5149, 8.56, 8.6069, 8.6556, 8.7061, 8.7584, 8.8125, 8.8684, 8.9261, 8.9856, 9.0469, 9.11, 9.174900000000001, 9.2416, 9.3101, 9.3804, 9.4525, 9.526399999999999, 9.6021, 9.6796, 9.7589, 9.84, 9.9229, 10.0076, 10.094100000000001, 10.1824, 10.2725, 10.3644, 10.4581, 10.5536, 10.6509, 10.75, 10.8509, 10.9536, 11.0581, 11.1644, 11.2725, 11.3824, 11.4941, 11.6076, 11.7229, 11.84, 11.9589, 12.0796, 12.202100000000002, 12.3264, 12.4525, 12.580400000000001, 12.7101, 12.8416, 12.974900000000002, 13.110000000000001, 13.2469, 13.3856, 13.5261, 13.6684, 13.8125, 13.958400000000001, 14.1061, 14.255600000000001, 14.4069, 14.560000000000002, 14.714900000000002, 14.8716, 15.030100000000001, 15.190399999999999, 15.3525, 15.5164, 15.6821, 15.849599999999999, 16.018900000000002, 16.19, 16.3629, 16.5376, 16.714100000000002, 16.892400000000002, 17.072499999999998, 17.2544, 17.4381, 17.6236, 17.8109]

# 测试集
# X_test = [0.02 * i for i in range(100, 200)]
# Y_test = [9 * x ** 2 + x + 8 for x in X_test]
X_test = [2.0, 2.02, 2.04, 2.06, 2.08, 2.1, 2.12, 2.14, 2.16, 2.18, 2.2, 2.22, 2.24, 2.2600000000000002, 2.2800000000000002, 2.3000000000000003, 2.32, 2.34, 2.36, 2.38, 2.4, 2.42, 2.44, 2.46, 2.48, 2.5, 2.52, 2.54, 2.56, 2.58, 2.6, 2.62, 2.64, 2.66, 2.68, 2.7, 2.72, 2.74, 2.7600000000000002, 2.7800000000000002, 2.8000000000000003, 2.82, 2.84, 2.86, 2.88, 2.9, 2.92, 2.94, 2.96, 2.98, 3.0, 3.02, 3.04, 3.06, 3.08, 3.1, 3.12, 3.14, 3.16, 3.18, 3.2, 3.22, 3.24, 3.2600000000000002, 3.2800000000000002, 3.3000000000000003, 3.3200000000000003, 3.34, 3.36, 3.38, 3.4, 3.42, 3.44, 3.46, 3.48, 3.5, 3.52, 3.54, 3.56, 3.58, 3.6, 3.62, 3.64, 3.66, 3.68, 3.7, 3.72, 3.74, 3.7600000000000002, 3.7800000000000002, 3.8000000000000003, 3.8200000000000003, 3.84, 3.86, 3.88, 3.9, 3.92, 3.94, 3.96, 3.98]
Y_test = [46.0, 46.7436, 47.4944, 48.2524, 49.0176, 49.79, 50.5696, 51.3564, 52.150400000000005, 52.951600000000006, 53.76000000000001, 54.57560000000001, 55.39840000000001, 56.228400000000015, 57.06560000000001, 57.910000000000004, 58.761599999999994, 59.62039999999999, 60.486399999999996, 61.3596, 62.239999999999995, 63.1276, 64.0224, 64.92439999999999, 65.83359999999999, 66.75, 67.67360000000001, 68.6044, 69.54240000000001, 70.4876, 71.44, 72.3996, 73.3664, 74.3404, 75.32160000000002, 76.31000000000002, 77.30560000000001, 78.3084, 79.31840000000001, 80.33560000000001, 81.36000000000001, 82.39159999999998, 83.4304, 84.47639999999998, 85.52959999999999, 86.59, 87.65759999999999, 88.73239999999998, 89.81439999999999, 90.9036, 92.0, 93.1036, 94.21440000000001, 95.3324, 96.4576, 97.59, 98.7296, 99.8764, 101.03040000000001, 102.19160000000002, 103.36000000000003, 104.53560000000002, 105.71840000000002, 106.90840000000001, 108.10560000000001, 109.31000000000002, 110.5216, 111.7404, 112.96639999999998, 114.19959999999998, 115.44, 116.68759999999999, 117.94239999999999, 119.20439999999999, 120.4736, 121.75, 123.03359999999999, 124.32440000000001, 125.6224, 126.9276, 128.24, 129.5596, 130.8864, 132.2204, 133.5616, 134.91000000000003, 136.26560000000003, 137.62840000000003, 138.99840000000003, 140.37560000000002, 141.76000000000002, 143.1516, 144.5504, 145.9564, 147.3696, 148.79, 150.21759999999998, 151.6524, 153.0944, 154.5436]
# print(X_test)
# print(Y_test)
#  臆测函数
def func(x):
    return w1 * x ** 2 + w2 * x + w3

# 损失函数 均方差
def loss(y_pred,y_true):
    return (y_pred - y_true ) ** 2

# 权重随机初始化
w1 = w2 = w3 = 0

# 学习率, 控制权重更新的跨度
# 学习率不能太大,否则会导致梯度爆炸,同时不能为0,否则会梯度消失,训练停止
# lr = 0 # 梯度消失 模型并没有进行学习
lr = 0.01
# lr = 1 # 梯度爆炸,模型训练时权重更新跨度太大

# 权重更新方式 每次使用n个样本进行权重更新 本次训练选择每20个样本更新一次权重
# 考虑到存在个别异常点的情况,尽量不要一个样本就更新一次权重
batch_size = 5

for epoch in range(10000):
    # 记录损失值
    epoch_loss = grad_w1 = grad_w2 = grad_w3 = cnt = 0
    for x,y_true in zip(X,Y):
        y_pred = func(x)
        epoch_loss += loss(y_pred,y_true)
        # 梯度计算
        # 计算方式:根据loss函数,针对对应权重进行求导
        # 针对 w1 求导 ((y_pred - y_true) ** 2)'w1 = 2 * (y_pred - y_true) * x ** 2
        # f(g(x))' = f'(g(x)) * g'(x)
        grad_w1 += 2 * (y_pred - y_true) * x ** 2
        grad_w2 += 2 * (y_pred - y_true) * x
        grad_w3 += 2 * (y_pred - y_true)
        cnt += 1
        # 优化器
        if cnt == batch_size:
            w1 -= lr * grad_w1 / batch_size
            w2 -= lr * grad_w2 / batch_size
            w3 -= lr * grad_w3 / batch_size
            cnt = grad_w1 = grad_w2 = grad_w3 = 0

    epoch_loss /= len(X)
    print("第%d轮, loss %f"%(epoch, epoch_loss))
    # 模型训练后损失值达到预期目标,结束训练
    if epoch_loss < 0.0001:
        break

print("训练后权重:", w1, w2, w3)
Y1 = [func(i) for i in X_test]

pyplot.scatter(X_test, Y_test, color="red")
pyplot.scatter(X_test, Y1)
pyplot.show()